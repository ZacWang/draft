
> 原文：https://mp.weixin.qq.com/s/wQv2Ca37evEQ_XWd3Y9v8g
> 黄仁勋参加 No Priors 访谈节目

主要观点：
- 没有任何物理定律可以阻止AI数据中心扩展到一百万芯片
- 超级摩尔定律：接下来的十年里，我们希望每年在整体规模上（而非单个芯片上）将性能提升两到三倍，从而使成本和能耗每年降低两到三倍。
- 具体实现路径：软硬件协同设计和数据中心级创新


## 超级摩尔定律

### 摩尔定律到达了瓶颈

摩尔定律的两个基本技术支柱：
- Dennard Scaling
- Carver Mead's VLSI Scaling

这两个支柱的相关技术都已经到了瓶颈，无法继续提升。

> 摩尔定律（芯片密度和性能的增长预期）：
> - 集成电路上的晶体管数量每两年翻一番。
> - 从而使得芯片上的计算能力每两年翻一番。

> Dennard Scaling（芯片密度和能耗的增长预期）：
> - 晶体管的尺寸缩小时，电压和电流成比例缩减。
> - 从而使得功率密度保持不变，即使频率提升。
> - 在 2000 年后，逐渐失效。特别是电流泄漏和其他量子效应开始显著增加，导致功耗密度不再随着缩放而减小。

> Carver Mead's VLSI Scaling（芯片集成度的增长预期）：
> - 基于几何缩放规则，设计方法适用于将芯片布局合理缩放，从而提高芯片密度和性能。
> VLSI 设计准则推动了 1980 年代之后 VLSI 技术的发展


### 超级摩尔定律的关键点

- 协同设计：软硬件协同，系统架构和软件架构
- 全栈优化：数据中心级创新
    - 挑战：低延迟和高吞吐的矛盾，需要发明一些新东西，like nvlink


### 训练和推理基础设施的相互转换
- 大部分 ChatGPT 服务在最近用于训练的同类型系统上进行推理
- 英伟达和生态致力于改进算法，使基础设施在一年内性能提高五倍（这会让新模型对算力的需求提升，也使得推理的算力需求提升，从而可以充分使用训练时的同类型算力？）
- 未来会是大小模型共同发展：通用大模型 + 蒸馏出来的各种领域小模型

### 构建和交付完整的数据中心
- 新的计算单位是数据中心，交付的性能指标是真实可达到的
- 数据中心即产品，尽管不直接销售数据中心
- 30 天内帮助建立起来

### xAI 的超级集群
- 马斯克的意志力 & 英伟达的工程能力
- 所有的组件、OEM、系统、我们与他们团队的软件集成、所有的网络模拟，都预先以数字孪生的方式模拟了他的网络配置
- 预先准备了他的供应链，预先安排了所有的网络布线
- 建立了一个小规模的版本作为参考，一边设备到达前进行测试

- 更大规模的超级集群：
    - 有 5-6 个团队在努力尝试：OpenAI、Anthropic、xAI、Google、Meta、微软等
    - 重新发明智能的奖赏太过重要，无法不去尝试
    - 没有物理定律的限制，但一切都会很难


### AI 芯片设计和英伟达的运作方式

- AI 协助芯片、软件设计，构建 Hopper
    - 相比人类，他们可以探索更大空间
    - 人类探索时，无法涵盖其他人的探索
    - 芯片如此之大，不是作为一个芯片设计的，而是像 1000 个芯片那样设计的，必须分别优化每一个

- 英伟达的变化
    - 重新发明了计算
    - 新的数据中心：往往是单租户的，不存储任何文件，只是在生成一些东西：tokens
        - 创造了一种新工具/机器：生成的 token 可以是各种东西，机器人的动作表达、氨基酸序列、化学链等等
        - 生成式人工智能 -> 人工智能工厂
        - 不再制造计算机了，而是在制造工厂（人工智能工厂），这个工厂生产 token，每个地方/公司都需要它

### 具身智能

- 两个 brownfield 机器人系统：
    - 自动驾驶汽车
    - 具身机器人

### AI for Science
- 被低估的领域
- 再过两三年，所有论文、科学工程突破，都会基于生成式人工智能



